{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing a U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_double_conv(inp_channels: int, output_channels: int):\n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv2d(inp_channels, output_channels, kernel_size=3),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(output_channels, output_channels, kernel_size=3),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "    return conv\n",
    "\n",
    "def crop_tensor(orignal_tensor, target_tensor):\n",
    "    orignal_size = orignal_tensor.size()[2]\n",
    "    target_size = target_tensor.size()[2]\n",
    "    delta = orignal_size - target_size\n",
    "    delta = delta//2\n",
    "    return orignal_tensor[:, :, delta:orignal_size-delta, delta:orignal_size-delta]\n",
    "\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.MaxPool_2x2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.down_conv_1 = build_double_conv(1, 64)\n",
    "        self.down_conv_2 = build_double_conv(64, 128)\n",
    "        self.down_conv_3 = build_double_conv(128, 256)\n",
    "        self.down_conv_4 = build_double_conv(256, 512)\n",
    "        self.down_conv_5 = build_double_conv(512, 1024)\n",
    "        \n",
    "        ## Second Part of the architecture\n",
    "        self.up_transpose_1 = nn.ConvTranspose2d(\n",
    "                            in_channels=1024,\n",
    "                            out_channels=512,\n",
    "                            kernel_size=2,\n",
    "                            stride = 2)\n",
    "        self.up_conv_1 = build_double_conv(1024, 512)\n",
    "        \n",
    "        self.up_transpose_2 = nn.ConvTranspose2d(\n",
    "                            in_channels=512,\n",
    "                            out_channels=256,\n",
    "                            kernel_size=2,\n",
    "                            stride = 2)\n",
    "        self.up_conv_2 = build_double_conv(512, 256)\n",
    "        \n",
    "        self.up_transpose_3 = nn.ConvTranspose2d(\n",
    "                            in_channels=256,\n",
    "                            out_channels=128,\n",
    "                            kernel_size=2,\n",
    "                            stride = 2)\n",
    "        self.up_conv_3 = build_double_conv(256, 128)\n",
    "        \n",
    "        self.up_transpose_4 = nn.ConvTranspose2d(\n",
    "                            in_channels=128,\n",
    "                            out_channels=64,\n",
    "                            kernel_size=2,\n",
    "                            stride = 2)\n",
    "        self.up_conv_4 = build_double_conv(128, 64)\n",
    "        \n",
    "        ## Output\n",
    "        self.output = nn.Conv2d(in_channels=64, out_channels=2, kernel_size=1)\n",
    "        \n",
    "    \n",
    "    def forward(self, image):\n",
    "        ## Encoder\n",
    "        x1 = self.down_conv_1(image) ## Skip connection\n",
    "        x2 = self.MaxPool_2x2(x1)\n",
    "        \n",
    "        x3 = self.down_conv_2(x2) ## Skip connection\n",
    "        x4 = self.MaxPool_2x2(x3)\n",
    "        \n",
    "        x5 = self.down_conv_3(x4) ## Skip connection\n",
    "        x6 = self.MaxPool_2x2(x5) \n",
    "        \n",
    "        x7 = self.down_conv_4(x6) ## Skip connection\n",
    "        x8 = self.MaxPool_2x2(x7)\n",
    "        \n",
    "        x9 = self.down_conv_5(x8)\n",
    "        \n",
    "        ## Decoder\n",
    "        x = self.up_transpose_1(x9)\n",
    "        y = crop_tensor(x7, x)\n",
    "        x = self.up_conv_1(torch.cat([x, y], axis=1))\n",
    "        \n",
    "        x = self.up_transpose_2(x)\n",
    "        y = crop_tensor(x5, x)\n",
    "        x = self.up_conv_2(torch.cat([x, y], axis=1))\n",
    "        \n",
    "        x = self.up_transpose_3(x)\n",
    "        y = crop_tensor(x3, x)\n",
    "        x = self.up_conv_3(torch.cat([x, y], axis=1))\n",
    "        \n",
    "        x = self.up_transpose_4(x)\n",
    "        y = crop_tensor(x1, x)\n",
    "        x = self.up_conv_4(torch.cat([x, y], axis=1))\n",
    "        \n",
    "        ## Output\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0771, -0.0800, -0.0728,  ..., -0.0756, -0.0763, -0.0764],\n",
       "          [-0.0751, -0.0731, -0.0729,  ..., -0.0740, -0.0707, -0.0783],\n",
       "          [-0.0756, -0.0729, -0.0755,  ..., -0.0755, -0.0748, -0.0759],\n",
       "          ...,\n",
       "          [-0.0724, -0.0765, -0.0723,  ..., -0.0778, -0.0732, -0.0745],\n",
       "          [-0.0753, -0.0744, -0.0774,  ..., -0.0784, -0.0741, -0.0751],\n",
       "          [-0.0781, -0.0761, -0.0787,  ..., -0.0726, -0.0768, -0.0796]],\n",
       "\n",
       "         [[-0.0725, -0.0709, -0.0767,  ..., -0.0739, -0.0784, -0.0722],\n",
       "          [-0.0727, -0.0750, -0.0772,  ..., -0.0726, -0.0729, -0.0741],\n",
       "          [-0.0752, -0.0756, -0.0733,  ..., -0.0728, -0.0716, -0.0722],\n",
       "          ...,\n",
       "          [-0.0740, -0.0731, -0.0741,  ..., -0.0731, -0.0704, -0.0760],\n",
       "          [-0.0707, -0.0752, -0.0701,  ..., -0.0741, -0.0705, -0.0753],\n",
       "          [-0.0721, -0.0786, -0.0725,  ..., -0.0763, -0.0759, -0.0739]]]],\n",
       "       grad_fn=<MkldnnConvolutionBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = torch.rand((1, 1, 572, 572))\n",
    "model = UNet()\n",
    "model(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
